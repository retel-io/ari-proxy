akka {
  loggers = ["akka.event.slf4j.Slf4jLogger"]
  loglevel = "DEBUG"
  stdout-loglevel = "DEBUG"
  logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
  event-handlers = ["akka.event.slf4j.Slf4jEventHandler"]
  log-dead-letters-during-shutdown = false
  coordinated-shutdown {
    phases {
      actor-system-terminate {
        timeout = 2s
        depends-on = [before-actor-system-terminate]
      }
    }
  }
  http {
    host-connection-pool {
      max-retries = 1
      max-connection-backoff = 1s
    }
    client {
      user-agent-header = ari-proxy
      connecting-timeout = 1s
      idle-timeout = 60s # the default

      websocket {
        periodic-keep-alive-mode = ping
        periodic-keep-alive-max-idle = 10s
      }
    }
  }

  kafka {
    producer {
      kafka-clients {
          max.in.flight.requests.per.connection = 1 # This should be set to ensure message order even in case of retries
          request.timeout.ms = 4000
          delivery.timeout.ms = 10000
      }
    }
    consumer {
    stop-timeout = 0 # consumer is drained explicitly
      kafka-clients {
        heartbeat.interval.ms = 3000
        session.timeout.ms = 10000
      }
      connection-checker.enable = true
    }
  }

}

service {
  name = "ari-proxy"
  websocket-uri = "ws://"${service.asterisk.server}"/ari/events?app="${service.stasis-app}"&api_key="${service.asterisk.user}":"${service.asterisk.password}

  rest {
    user = ${service.asterisk.user}
    password = ${service.asterisk.password}
    uri = "http://"${service.asterisk.server}"/ari"
  }

  kafka {
    security {
      protocol = "PLAIN"
      user = ""
      password = ""
    }

    auto-offset-reset = "earliest"
    parallel-consumer-max-concurrency = 1
  }
}
